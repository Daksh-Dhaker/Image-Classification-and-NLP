{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMc3fFq1ya23Q02JcC6Md3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daksh-Dhaker/Neural-Networks/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "59nOx5TIx3cC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Pxo4BA8IyE_5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"shakespeare.txt\",'r').read()"
      ],
      "metadata": {
        "id": "SR9DHajRyVOo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))"
      ],
      "metadata": {
        "id": "H81OAP4OzRob"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab) # number of unique characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS46328yzWJt",
        "outputId": "bb31f16e-772c-457a-8498-acd482d9e9b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Processing (Vectorizing the text and creating encoding dictionary)\n",
        "for pair in enumerate(vocab):\n",
        "  print(pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdq9w1eAz4Zq",
        "outputId": "1a818b89-54e6-44d4-a722-2a28e6a48155"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '\\n')\n",
            "(1, ' ')\n",
            "(2, '!')\n",
            "(3, '\"')\n",
            "(4, '&')\n",
            "(5, \"'\")\n",
            "(6, '(')\n",
            "(7, ')')\n",
            "(8, ',')\n",
            "(9, '-')\n",
            "(10, '.')\n",
            "(11, '0')\n",
            "(12, '1')\n",
            "(13, '2')\n",
            "(14, '3')\n",
            "(15, '4')\n",
            "(16, '5')\n",
            "(17, '6')\n",
            "(18, '7')\n",
            "(19, '8')\n",
            "(20, '9')\n",
            "(21, ':')\n",
            "(22, ';')\n",
            "(23, '<')\n",
            "(24, '>')\n",
            "(25, '?')\n",
            "(26, 'A')\n",
            "(27, 'B')\n",
            "(28, 'C')\n",
            "(29, 'D')\n",
            "(30, 'E')\n",
            "(31, 'F')\n",
            "(32, 'G')\n",
            "(33, 'H')\n",
            "(34, 'I')\n",
            "(35, 'J')\n",
            "(36, 'K')\n",
            "(37, 'L')\n",
            "(38, 'M')\n",
            "(39, 'N')\n",
            "(40, 'O')\n",
            "(41, 'P')\n",
            "(42, 'Q')\n",
            "(43, 'R')\n",
            "(44, 'S')\n",
            "(45, 'T')\n",
            "(46, 'U')\n",
            "(47, 'V')\n",
            "(48, 'W')\n",
            "(49, 'X')\n",
            "(50, 'Y')\n",
            "(51, 'Z')\n",
            "(52, '[')\n",
            "(53, ']')\n",
            "(54, '_')\n",
            "(55, '`')\n",
            "(56, 'a')\n",
            "(57, 'b')\n",
            "(58, 'c')\n",
            "(59, 'd')\n",
            "(60, 'e')\n",
            "(61, 'f')\n",
            "(62, 'g')\n",
            "(63, 'h')\n",
            "(64, 'i')\n",
            "(65, 'j')\n",
            "(66, 'k')\n",
            "(67, 'l')\n",
            "(68, 'm')\n",
            "(69, 'n')\n",
            "(70, 'o')\n",
            "(71, 'p')\n",
            "(72, 'q')\n",
            "(73, 'r')\n",
            "(74, 's')\n",
            "(75, 't')\n",
            "(76, 'u')\n",
            "(77, 'v')\n",
            "(78, 'w')\n",
            "(79, 'x')\n",
            "(80, 'y')\n",
            "(81, 'z')\n",
            "(82, '|')\n",
            "(83, '}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind = {char:ind for ind,char in enumerate(vocab)} # mapping chars to numbers(0-83)"
      ],
      "metadata": {
        "id": "fP6dY95_0fjl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "metadata": {
        "id": "UPk5ROdb0yGf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text]) # complete text with chars replaced by numbers"
      ],
      "metadata": {
        "id": "dCuqq9by00AR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating batches\n",
        "seq_len = 120\n"
      ],
      "metadata": {
        "id": "Yt6d2A6U1bpY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_seq = len(text)//(seq_len+1)"
      ],
      "metadata": {
        "id": "dPsANQ6k2mma"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I83Tp2T-2vSR",
        "outputId": "79c67893-6b56-4578-f51c-d12f00e628b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "metadata": {
        "id": "snNLG09t2xEV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(char_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSRsvfbB2_Vs",
        "outputId": "36a7deef-98df-43a7-a034-29f5bd6fd4b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder = True)"
      ],
      "metadata": {
        "id": "y7PzDh3T3DcD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "  input_txt = seq[:-1]# Hello my nam\n",
        "  target_txt = seq[1:]# ello my name\n",
        "  return input_txt,target_txt"
      ],
      "metadata": {
        "id": "Fv7DZ9v43XWx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "ahdHP9gP4IvQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "hsxaq4u34OiZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder = True)"
      ],
      "metadata": {
        "id": "QFuXNVWb4wWD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the model\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 64"
      ],
      "metadata": {
        "id": "EL3CNiIt5ACq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "Wtn95P1L5j0U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "JBpnya0A5qR5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true,y_pred,from_logits = True)"
      ],
      "metadata": {
        "id": "4ICN3-Aw51yz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense\n",
        "\n",
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim,batch_input_shape =[batch_size,None]))\n",
        "  model.add(GRU(rnn_neurons,return_sequences = True,stateful = True,recurrent_initializer = 'glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "  model.compile(optimizer ='adam',loss = sparse_cat_loss)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Rvw0D60z6N9_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size = vocab_size,embed_dim = embed_dim,rnn_neurons = rnn_neurons,batch_size = batch_size )"
      ],
      "metadata": {
        "id": "0Fqnig_k7v2G"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgpldhYV8ADK",
        "outputId": "0429acbd-1215-4ad1-8f71-fbed3b6322b1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3452820 (13.17 MB)\n",
            "Trainable params: 3452820 (13.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)"
      ],
      "metadata": {
        "id": "B06cGM8j8DiH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples =1)"
      ],
      "metadata": {
        "id": "cVPUXzQd9oN3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices,axis =-1).numpy()"
      ],
      "metadata": {
        "id": "xJ0O2IWa9x2X"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ind_to_char[sampled_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEqvKpvV-QVU",
        "outputId": "c62479eb-c338-440d-855b-de192472239b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A', ' ', 'V', 'x', \"'\", 'B', 'r', ')', '!', '\\n', 'a', '3', 'r',\n",
              "       'Y', 'T', 'd', 'E', 'K', 'u', 'V', '4', 'q', 'S', '>', 'r', 'B',\n",
              "       's', 'z', 'X', 'x', 'Y', 'A', 'u', 'U', 'S', ';', 's', \"'\", '0',\n",
              "       'a', ',', 'C', '6', 'Y', 'k', '6', '_', 'n', 'z', 'g', ';', 'L',\n",
              "       'L', 'n', 'g', '<', ';', '>', 'C', 'h', '?', '\\n', 'u', 'f', 'l',\n",
              "       'O', 'D', '_', '0', '&', '?', 'j', 'c', 'K', 'z', '1', 'h', 'Q',\n",
              "       'H', 'M', '\"', 'E', 'x', 'g', ';', '2', 'O', 'W', 'E', 'e', 'Q',\n",
              "       '<', '<', 'h', 'S', 'i', 'C', 'n', 'm', '_', '0', 'A', 'M', 'k',\n",
              "       'i', 'R', \"'\", '4', 'U', 'F', '&', 'R', '9', '3', 'x', 'k', 'Z',\n",
              "       'G', 'V', 'b'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs = 30\n",
        "# model.fit(dataset,epochs = epochs)\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "2rR7QSqv-lNo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)"
      ],
      "metadata": {
        "id": "v8czdzlt-xeJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('shakespeare_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "04gk6d2gAERf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_seed,gen_size = 500,temp =1.0):\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples =1)[-1,0].numpy()\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed+\"\".join(text_generated))"
      ],
      "metadata": {
        "id": "RDwmSRJuBU5F"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"JULIET\",gen_size =100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8NWC0WDQJ1",
        "outputId": "2e93a4c0-caa5-4a77-8f00-c49a438dcb63"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULIET6\n",
            "\n",
            "Sense? conclusion! and I hold him sleep.\n",
            "  VALENTINE. Thus, in the dead Lopitus of Venice,\n",
            "    An\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HxgWv1erDcYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}